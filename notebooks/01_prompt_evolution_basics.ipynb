{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Prompt Evolution with SCOPE\n",
        "\n",
        "Welcome to this tutorial on **automatic prompt optimization**!\n",
        "\n",
        "## What You'll Learn\n",
        "\n",
        "In this notebook, you'll discover how AI systems can automatically improve their own prompts through observation and learning. We'll use a simple information extraction task to demonstrate:\n",
        "\n",
        "- üìö How SCOPE (Self-Correcting Optimal Prompt Evolution) works\n",
        "- üîÑ How prompts evolve automatically over time\n",
        "- üìä How to measure improvement through iterative learning\n",
        "- üéØ Real-world application with LangChain\n",
        "\n",
        "## Context\n",
        "\n",
        "Traditional AI systems use **static prompts** - they never change or improve. But what if your AI could learn from experience and automatically optimize its own instructions? That's exactly what SCOPE enables.\n",
        "\n",
        "Think of it like a student who:\n",
        "1. Completes a task\n",
        "2. Reviews what went well and what didn't\n",
        "3. Updates their approach for next time\n",
        "4. Gets better with each attempt\n",
        "\n",
        "SCOPE does this automatically, with no manual prompt engineering required!\n",
        "\n",
        "## About This Tutorial\n",
        "\n",
        "This notebook uses a **simple information extraction task** to teach SCOPE fundamentals. The same principles apply to complex systems - in fact, this repository includes a production research assistant with:\n",
        "- üéØ 5 agents learning simultaneously\n",
        "- üéì Source quality assessment (academic vs blog detection)\n",
        "- üìà +31% quality improvement in just 5 iterations\n",
        "\n",
        "We start simple here so you can focus on **how SCOPE works**, then you can explore the advanced features!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ‚ö†Ô∏è Important: Using the Right Environment\n",
        "\n",
        "This notebook requires the project environment.\n",
        "\n",
        "**Before running:** Activate the project `.venv`:\n",
        "```bash\n",
        "source .venv/bin/activate  # In project root\n",
        "```\n",
        "\n",
        "**In VS Code/Cursor:** The `.venv` is auto-detected - just open and run!\n",
        "\n",
        "**Verify below:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "print(\"üêç Python:\", sys.executable)\n",
        "print(\"üìÅ Directory:\", Path.cwd())\n",
        "\n",
        "# Check if using project .venv\n",
        "if \".venv\" in sys.executable:\n",
        "    print(\"\\n‚úÖ Correct! Using project .venv\")\n",
        "else:\n",
        "    print(\"\\n‚ö†Ô∏è  Not using project .venv\")\n",
        "    print(\"   Run: source .venv/bin/activate\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup\n",
        "\n",
        "First, let's install the required packages and set up our environment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%capture --no-stderr\n",
        "%pip install --quiet -U langchain_openai langchain_core scope-optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os, getpass\n",
        "\n",
        "def _set_env(var: str):\n",
        "    if not os.environ.get(var):\n",
        "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
        "\n",
        "_set_env(\"OPENAI_API_KEY\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## The Concept: Before and After\n",
        "\n",
        "Let's understand what we're building:\n",
        "\n",
        "### Without SCOPE (Traditional Approach)\n",
        "```\n",
        "Static Prompt ‚Üí LLM ‚Üí Output\n",
        "     ‚Üì\n",
        "  Never changes!\n",
        "```\n",
        "\n",
        "### With SCOPE (Evolving Approach)\n",
        "```\n",
        "Initial Prompt ‚Üí LLM ‚Üí Output\n",
        "      ‚Üì                  ‚Üì\n",
        "      ‚Üì          SCOPE Observes\n",
        "      ‚Üì                  ‚Üì\n",
        "      ‚Üì          Learns Patterns\n",
        "      ‚Üì                  ‚Üì\n",
        "Improved Prompt ‚Üê Updates Rules\n",
        "```\n",
        "\n",
        "The magic happens in the learning loop - SCOPE observes what works and what doesn't, then automatically generates improvement rules!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Our Simple Task: Information Extraction\n",
        "\n",
        "We'll use information extraction as our example because:\n",
        "- ‚úÖ It's easy to understand\n",
        "- ‚úÖ Results are measurable\n",
        "- ‚úÖ Improvements are visible\n",
        "\n",
        "We'll ask the AI to extract information like emails, names, and phone numbers from text. As it completes tasks, SCOPE will learn how to do this better."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: The Base Prompt (Before Learning)\n",
        "\n",
        "Let's start with a simple, basic prompt. This is what the AI begins with - no optimization yet."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìã Base Prompt (intentionally simple):\n",
            "You are an information extraction specialist.\n",
            "Extract the requested information from the provided text.\n",
            "\n",
            "## Core Instructions:\n",
            "- Extract only what is requested\n",
            "- If information is not present, respond with \"Not found\"\n",
            "\n",
            "\n",
            "üí° This basic prompt will allow SCOPE to discover best practices through observation!\n"
          ]
        }
      ],
      "source": [
        "BASE_EXTRACTION_PROMPT = \"\"\"You are an information extraction specialist.\n",
        "Extract the requested information from the provided text.\n",
        "\n",
        "## Core Instructions:\n",
        "- Extract only what is requested\n",
        "- If information is not present, respond with \"Not found\"\n",
        "\"\"\"\n",
        "\n",
        "print(\"üìã Base Prompt (intentionally simple):\")\n",
        "print(BASE_EXTRACTION_PROMPT)\n",
        "print(\"\\nüí° This basic prompt will allow SCOPE to discover best practices through observation!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This prompt is intentionally basic! It doesn't specify:\n",
        "- How to handle email case (should `SUPPORT@COMPANY.COM` be lowercase?)\n",
        "- Whether to remove brackets/formatting from emails (`<INFO@HELP.NET>`)\n",
        "- How to standardize dates (`12/25/2024` vs `January 1st 2025` vs `2025-02-14`)\n",
        "- Which phone number format to use (`(555)123.4567` vs `555 987 6543`)\n",
        "- How to ensure consistency when the same instruction is repeated\n",
        "\n",
        "**This is where SCOPE comes in!** When the model handles similar tasks inconsistently, SCOPE observes the patterns and automatically learns formatting rules to standardize outputs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### üí° What Makes This Demo Work?\n",
        "\n",
        "The tasks use **repeated similar instructions** to expose formatting inconsistencies:\n",
        "\n",
        "**Task 1 & 2: Email Extraction (Same Task, Different Data)**\n",
        "- `SUPPORT@COMPANY.COM` vs `sales@test.org` ‚Üí Mixed case needs normalization\n",
        "- `<INFO@HELP.NET>` vs plain text ‚Üí Inconsistent formatting\n",
        "- SCOPE will learn: \"Always lowercase emails, remove brackets\"\n",
        "\n",
        "**Task 3 & 4: Date Extraction (Proven Pattern!)**\n",
        "- `12/25/2024` vs `January 1st 2025` vs `2025-02-14` ‚Üí Mixed formats\n",
        "- `March 15th 2025` vs `04/20/2025` vs `2025-05-30` ‚Üí More variety\n",
        "- SCOPE will learn: \"Standardize all dates to YYYY-MM-DD\"\n",
        "\n",
        "**Task 5: Phone Numbers**\n",
        "- `1-555-CALL-NOW`, `(555)123.4567`, `555 987 6543` ‚Üí Messy formats\n",
        "- SCOPE will learn: \"Clean and standardize phone formats\"\n",
        "\n",
        "**Why this strategy works:**\n",
        "- **Repetition**: Same instruction twice forces consistency decisions\n",
        "- **Visible input inconsistencies**: Mixed formats that clearly need fixing\n",
        "- **First run**: Model handles each case separately (inconsistent)\n",
        "- **SCOPE observes**: Identifies the pattern across similar tasks\n",
        "- **Second run**: Applies learned rules consistently!\n",
        "\n",
        "The key: **Repeated task types** make inconsistencies obvious and improvements measurable."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Define Extraction Tasks\n",
        "\n",
        "Let's create a variety of extraction tasks. Each one will teach SCOPE something different:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Created 5 extraction tasks designed for visible learning\n",
            "\n",
            "Key improvements:\n",
            "  ‚Ä¢ Task 1 & 2: Same instruction, different data ‚Üí tests consistency\n",
            "  ‚Ä¢ Task 3 & 4: Dates with mixed formats ‚Üí proven to standardize\n",
            "  ‚Ä¢ Task 5: Messy phone formats ‚Üí should clean up\n",
            "  ‚Ä¢ Uppercase emails (SUPPORT@COMPANY.COM) ‚Üí should normalize\n",
            "\n",
            "üí° These tasks expose inconsistencies that SCOPE can learn to fix!\n"
          ]
        }
      ],
      "source": [
        "EXTRACTION_TASKS = [\n",
        "    # Task 1: Emails - force the model to handle inconsistent data first\n",
        "    {\n",
        "        \"instruction\": \"Extract all email addresses in a clean list\",\n",
        "        \"text\": \"Reach us at: SUPPORT@COMPANY.COM, Sales: sales@test.org, or Info <INFO@HELP.NET>\"\n",
        "    },\n",
        "    \n",
        "    # Task 2: Multiple extractions - test if model maintains learned patterns\n",
        "    {\n",
        "        \"instruction\": \"Extract all email addresses in a clean list\", \n",
        "        \"text\": \"Team: Alice.Brown@TECH.COM, bob.smith@startup.io, Contact: HR@BUSINESS.ORG\"\n",
        "    },\n",
        "    \n",
        "    # Task 3: Dates - proven to work! Keep this one\n",
        "    {\n",
        "        \"instruction\": \"Extract dates\",\n",
        "        \"text\": \"Important dates: 12/25/2024, January 1st 2025, and 2025-02-14\"\n",
        "    },\n",
        "    \n",
        "    # Task 4: Second date task - test consistency\n",
        "    {\n",
        "        \"instruction\": \"Extract dates\",\n",
        "        \"text\": \"Deadlines: March 15th 2025, 04/20/2025, and 2025-05-30\"\n",
        "    },\n",
        "    \n",
        "    # Task 5: Phone numbers with messy formatting\n",
        "    {\n",
        "        \"instruction\": \"Extract phone numbers\",\n",
        "        \"text\": \"Contact: 1-555-CALL-NOW (555-2255), office (555)123.4567, or mobile: 555 987 6543\"\n",
        "    },\n",
        "]\n",
        "\n",
        "print(f\"‚úÖ Created {len(EXTRACTION_TASKS)} extraction tasks designed for visible learning\")\n",
        "print(\"\\nKey improvements:\")\n",
        "print(\"  ‚Ä¢ Task 1 & 2: Same instruction, different data ‚Üí tests consistency\")\n",
        "print(\"  ‚Ä¢ Task 3 & 4: Dates with mixed formats ‚Üí proven to standardize\")\n",
        "print(\"  ‚Ä¢ Task 5: Messy phone formats ‚Üí should clean up\")\n",
        "print(\"  ‚Ä¢ Uppercase emails (SUPPORT@COMPANY.COM) ‚Üí should normalize\")\n",
        "print(\"\\nüí° These tasks expose inconsistencies that SCOPE can learn to fix!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Set Up LangChain\n",
        "\n",
        "Now let's create our LangChain chat model. We'll use GPT-4o for high-quality extractions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ LangChain ChatOpenAI initialized\n",
            "   Model: gpt-4o\n",
            "   Temperature: 0 (deterministic)\n"
          ]
        }
      ],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.messages import SystemMessage, HumanMessage\n",
        "\n",
        "# Initialize the chat model\n",
        "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
        "\n",
        "print(\"‚úÖ LangChain ChatOpenAI initialized\")\n",
        "print(\"   Model: gpt-4o\")\n",
        "print(\"   Temperature: 0 (deterministic)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Initialize SCOPE\n",
        "\n",
        "Here's where the magic begins! SCOPE will observe each task completion and learn improvement patterns."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ SCOPE Optimizer initialized\n",
            "   üìä Quality analysis: Enabled\n",
            "   üíæ Learning history: Stored\n",
            "   ‚ö° Mode: Efficiency (fast learning)\n"
          ]
        }
      ],
      "source": [
        "from scope import SCOPEOptimizer\n",
        "from scope.models import create_openai_model\n",
        "\n",
        "# Create SCOPE's model (for analyzing and learning)\n",
        "scope_model = create_openai_model(\n",
        "    model=\"gpt-4o\",\n",
        "    api_key=os.environ[\"OPENAI_API_KEY\"]\n",
        ")\n",
        "\n",
        "# Initialize SCOPE optimizer\n",
        "optimizer = SCOPEOptimizer(\n",
        "    synthesizer_model=scope_model,\n",
        "    exp_path=\"./scope_data\",  # Where to save learned rules\n",
        "    enable_quality_analysis=True,  # Analyze quality after each task\n",
        "    quality_analysis_frequency=1,  # Check every task\n",
        "    synthesis_mode=\"efficiency\",  # Fast learning mode\n",
        "    store_history=True  # Keep learning history\n",
        ")\n",
        "\n",
        "print(\"‚úÖ SCOPE Optimizer initialized\")\n",
        "print(\"   üìä Quality analysis: Enabled\")\n",
        "print(\"   üíæ Learning history: Stored\")\n",
        "print(\"   ‚ö° Mode: Efficiency (fast learning)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### What do these parameters mean?\n",
        "\n",
        "- **enable_quality_analysis**: After each task, SCOPE analyzes if the output could be better\n",
        "- **quality_analysis_frequency**: How often to check (1 = every task)\n",
        "- **synthesis_mode**: \"efficiency\" learns quickly, \"thoroughness\" is more thorough (7-dimension analysis)\n",
        "- **store_history**: Keeps a record of all learning events\n",
        "\n",
        "### Why \"efficiency\" mode for this tutorial?\n",
        "\n",
        "For this educational tutorial, we use **\"efficiency\"** mode because:\n",
        "- ‚úÖ Faster learning (good for quick demonstrations)\n",
        "- ‚úÖ Clear, straightforward rules\n",
        "- ‚úÖ Perfect for understanding SCOPE fundamentals\n",
        "\n",
        "The research assistant (`main.py`) uses **\"thoroughness\"** mode for production:\n",
        "- üéØ More detailed analysis (7 dimensions)\n",
        "- üéØ Higher quality rules\n",
        "- üéØ Better for complex, multi-agent systems"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: First Run - Observe Learning\n",
        "\n",
        "Let's run through our tasks and watch SCOPE learn in real-time!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üöÄ BEFORE LEARNING (Initial Run)\n",
            "\n",
            "======================================================================\n",
            "\n",
            "üìù Task 1/5\n",
            "Instruction: Extract all email addresses in a clean list\n",
            "Text: Reach us at: SUPPORT@COMPANY.COM, Sales: sales@test.org, or Info <INFO@HELP.NET>\n",
            "\n",
            "‚úì Output: - SUPPORT@COMPANY.COM\n",
            "- sales@test.org\n",
            "- INFO@HELP.NET\n",
            "\n",
            "üìö SCOPE LEARNED (STRATEGIC):\n",
            "   Convert all extracted emails to lowercase to maintain consistency....\n",
            "\n",
            "----------------------------------------------------------------------\n",
            "\n",
            "üìù Task 2/5\n",
            "Instruction: Extract all email addresses in a clean list\n",
            "Text: Team: Alice.Brown@TECH.COM, bob.smith@startup.io, Contact: HR@BUSINESS.ORG\n",
            "\n",
            "‚úì Output: - alice.brown@tech.com\n",
            "- bob.smith@startup.io\n",
            "- hr@business.org\n",
            "\n",
            "----------------------------------------------------------------------\n",
            "\n",
            "üìù Task 3/5\n",
            "Instruction: Extract dates\n",
            "Text: Important dates: 12/25/2024, January 1st 2025, and 2025-02-14\n",
            "\n",
            "‚úì Output: 12/25/2024, January 1st 2025, 2025-02-14\n",
            "\n",
            "üìö SCOPE LEARNED (STRATEGIC):\n",
            "   Always use a consistent date format, such as YYYY-MM-DD, for all extracted dates....\n",
            "\n",
            "----------------------------------------------------------------------\n",
            "\n",
            "üìù Task 4/5\n",
            "Instruction: Extract dates\n",
            "Text: Deadlines: March 15th 2025, 04/20/2025, and 2025-05-30\n",
            "\n",
            "‚úì Output: 2025-03-15, 2025-04-20, 2025-05-30\n",
            "\n",
            "üìö SCOPE LEARNED (STRATEGIC):\n",
            "   Always verify and clearly delimit output to ensure extracted dates align precisely with the expected format....\n",
            "\n",
            "----------------------------------------------------------------------\n",
            "\n",
            "üìù Task 5/5\n",
            "Instruction: Extract phone numbers\n",
            "Text: Contact: 1-555-CALL-NOW (555-2255), office (555)123.4567, or mobile: 555 987 6543\n",
            "\n",
            "‚úì Output: 1-555-CALL-NOW (555-2255), (555)123.4567, 555 987 6543\n",
            "\n",
            "üìö SCOPE LEARNED (STRATEGIC):\n",
            "   Normalize extracted phone numbers to a consistent format, e.g., (NNN) NNN-NNNN....\n",
            "\n",
            "----------------------------------------------------------------------\n",
            "\n",
            "‚úÖ Completed 5 tasks\n",
            "üìö SCOPE learning events: 4\n"
          ]
        }
      ],
      "source": [
        "import asyncio\n",
        "\n",
        "async def extract_with_scope(instruction, text, task_id):\n",
        "    \"\"\"Extract information and let SCOPE observe.\"\"\"\n",
        "    \n",
        "    # Get current prompt (starts with base, evolves over time)\n",
        "    strategic_rules = optimizer.get_strategic_rules_for_agent(\"info_extractor\")\n",
        "    current_prompt = BASE_EXTRACTION_PROMPT\n",
        "    if strategic_rules:\n",
        "        current_prompt += f\"\\n\\n## Strategic Guidelines (Learned):\\n{strategic_rules}\"\n",
        "    \n",
        "    # Create messages\n",
        "    messages = [\n",
        "        SystemMessage(content=current_prompt),\n",
        "        HumanMessage(content=f\"{instruction}\\n\\nText: {text}\")\n",
        "    ]\n",
        "    \n",
        "    # Get response from LLM\n",
        "    response = llm.invoke(messages)\n",
        "    output = response.content\n",
        "    \n",
        "    # Let SCOPE observe and learn\n",
        "    result = await optimizer.on_step_complete(\n",
        "        agent_name=\"info_extractor\",\n",
        "        agent_role=\"Information Extraction Specialist\",\n",
        "        task=f\"{instruction} | Text: {text}\",\n",
        "        model_output=output,\n",
        "        observations=f\"Extracted from: '{text[:50]}...'\",\n",
        "        error=None,\n",
        "        current_system_prompt=current_prompt,\n",
        "        task_id=task_id\n",
        "    )\n",
        "    \n",
        "    return output, result\n",
        "\n",
        "# Run the tasks\n",
        "print(\"üöÄ BEFORE LEARNING (Initial Run)\\n\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "learning_events = []\n",
        "first_run_outputs = []  # Store outputs for comparison\n",
        "\n",
        "for i, task in enumerate(EXTRACTION_TASKS, 1):\n",
        "    print(f\"\\nüìù Task {i}/{len(EXTRACTION_TASKS)}\")\n",
        "    print(f\"Instruction: {task['instruction']}\")\n",
        "    print(f\"Text: {task['text']}\")\n",
        "    \n",
        "    # Run extraction\n",
        "    output, learning_result = await extract_with_scope(\n",
        "        task['instruction'],\n",
        "        task['text'],\n",
        "        f\"task_{i}\"\n",
        "    )\n",
        "    \n",
        "    first_run_outputs.append(output)  # Store for comparison\n",
        "    print(f\"\\n‚úì Output: {output}\")\n",
        "    \n",
        "    # Check if SCOPE learned something\n",
        "    if learning_result:\n",
        "        guideline, guideline_type = learning_result\n",
        "        learning_events.append({\"task\": i, \"type\": guideline_type, \"rule\": guideline})\n",
        "        print(f\"\\nüìö SCOPE LEARNED ({guideline_type.upper()}):\")\n",
        "        print(f\"   {guideline[:120]}...\")\n",
        "    \n",
        "    print(\"\\n\" + \"-\" * 70)\n",
        "\n",
        "print(f\"\\n‚úÖ Completed {len(EXTRACTION_TASKS)} tasks\")\n",
        "print(f\"üìö SCOPE learning events: {len(learning_events)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìä Learning Summary\n",
            "\n",
            "======================================================================\n",
            "\n",
            "Total learning events: 4\n",
            "\n",
            "Task 1 - STRATEGIC:\n",
            "  Convert all extracted emails to lowercase to maintain consistency....\n",
            "\n",
            "Task 3 - STRATEGIC:\n",
            "  Always use a consistent date format, such as YYYY-MM-DD, for all extracted dates....\n",
            "\n",
            "Task 4 - STRATEGIC:\n",
            "  Always verify and clearly delimit output to ensure extracted dates align precisely with the expected...\n",
            "\n",
            "Task 5 - STRATEGIC:\n",
            "  Normalize extracted phone numbers to a consistent format, e.g., (NNN) NNN-NNNN....\n",
            "\n",
            "\n",
            "======================================================================\n",
            "EVOLVED PROMPT (After Learning)\n",
            "======================================================================\n",
            "You are an information extraction specialist.\n",
            "Extract the requested information from the provided text.\n",
            "\n",
            "## Core Instructions:\n",
            "- Extract only what is requested\n",
            "- If information is not present, respond with \"Not found\"\n",
            "\n",
            "\n",
            "## Strategic Guidelines (Learned):\n",
            "\n",
            "## Strategic Guidelines (Learned Best Practices):\n",
            "These are high-confidence rules learned from previous tasks:\n",
            "\n",
            "### Data Validation:\n",
            "- Convert all extracted emails to lowercase to maintain consistency.\n",
            "- Always use a consistent date format, such as YYYY-MM-DD, for all extracted dates.\n",
            "- Always verify and clearly delimit output to ensure extracted dates align precisely with the expected format.\n",
            "- Normalize extracted phone numbers to a consistent format, e.g., (NNN) NNN-NNNN.\n"
          ]
        }
      ],
      "source": [
        "print(\"üìä Learning Summary\\n\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "if learning_events:\n",
        "    print(f\"\\nTotal learning events: {len(learning_events)}\\n\")\n",
        "    \n",
        "    for event in learning_events:\n",
        "        print(f\"Task {event['task']} - {event['type'].upper()}:\")\n",
        "        print(f\"  {event['rule'][:100]}...\")\n",
        "        print()\n",
        "else:\n",
        "    print(\"No learning events recorded.\")\n",
        "\n",
        "# Get the complete evolved prompt\n",
        "strategic_rules = optimizer.get_strategic_rules_for_agent(\"info_extractor\")\n",
        "evolved_prompt = BASE_EXTRACTION_PROMPT\n",
        "if strategic_rules:\n",
        "    evolved_prompt += f\"\\n\\n## Strategic Guidelines (Learned):\\n{strategic_rules}\"\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"EVOLVED PROMPT (After Learning)\")\n",
        "print(\"=\" * 70)\n",
        "print(evolved_prompt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 7: Compare Before and After\n",
        "\n",
        "Now let's run the same tasks again with the evolved prompt!\n",
        "\n",
        "**What to watch for:**\n",
        "- Are outputs more normalized (lowercase emails, consistent formatting)?\n",
        "- Do we see fewer learning events (meaning the prompt is already better)?\n",
        "- Can you spot visible improvements in the outputs?\n",
        "\n",
        "Let's find out:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üîÑ AFTER LEARNING (Second Run with Evolved Prompt)\n",
            "\n",
            "======================================================================\n",
            "\n",
            "üìù Task 1/5\n",
            "‚úì Output: support@company.com  \n",
            "sales@test.org  \n",
            "info@help.net\n",
            "üìö New learning event\n",
            "\n",
            "üìù Task 2/5\n",
            "‚úì Output: alice.brown@tech.com  \n",
            "bob.smith@startup.io  \n",
            "hr@business.org\n",
            "‚úì No new learning needed (prompt already optimized!)\n",
            "\n",
            "üìù Task 3/5\n",
            "‚úì Output: 2024-12-25, 2025-01-01, 2025-02-14\n",
            "üìö New learning event\n",
            "\n",
            "üìù Task 4/5\n",
            "‚úì Output: 2025-03-15, 2025-04-20, 2025-05-30\n",
            "‚úì No new learning needed (prompt already optimized!)\n",
            "\n",
            "üìù Task 5/5\n",
            "‚úì Output: (555) 123-4567  \n",
            "555-987-6543\n",
            "‚úì No new learning needed (prompt already optimized!)\n",
            "\n",
            "======================================================================\n",
            "üìä SIDE-BY-SIDE COMPARISON\n",
            "======================================================================\n",
            "\n",
            "üìù Task 1: Extract all email addresses in a clean list\n",
            "   Text: Reach us at: SUPPORT@COMPANY.COM, Sales: sales@test.org, or ...\n",
            "\n",
            "   ‚ùå Before: - SUPPORT@COMPANY.COM\n",
            "- sales@test.org\n",
            "- INFO@HELP.NET\n",
            "   ‚úÖ After:  support@company.com  \n",
            "sales@test.org  \n",
            "info@help.net\n",
            "   üí° Improvement: Output is now more consistent/normalized\n",
            "\n",
            "üìù Task 2: Extract all email addresses in a clean list\n",
            "   Text: Team: Alice.Brown@TECH.COM, bob.smith@startup.io, Contact: H...\n",
            "\n",
            "   ‚ùå Before: - alice.brown@tech.com\n",
            "- bob.smith@startup.io\n",
            "- hr@business.org\n",
            "   ‚úÖ After:  alice.brown@tech.com  \n",
            "bob.smith@startup.io  \n",
            "hr@business.org\n",
            "   üí° Improvement: Output is now more consistent/normalized\n",
            "\n",
            "üìù Task 3: Extract dates\n",
            "   Text: Important dates: 12/25/2024, January 1st 2025, and 2025-02-1...\n",
            "\n",
            "   ‚ùå Before: 12/25/2024, January 1st 2025, 2025-02-14\n",
            "   ‚úÖ After:  2024-12-25, 2025-01-01, 2025-02-14\n",
            "   üí° Improvement: Output is now more consistent/normalized\n",
            "\n",
            "üìù Task 5: Extract phone numbers\n",
            "   Text: Contact: 1-555-CALL-NOW (555-2255), office (555)123.4567, or...\n",
            "\n",
            "   ‚ùå Before: 1-555-CALL-NOW (555-2255), (555)123.4567, 555 987 6543\n",
            "   ‚úÖ After:  (555) 123-4567  \n",
            "555-987-6543\n",
            "   üí° Improvement: Output is now more consistent/normalized\n",
            "\n",
            "======================================================================\n",
            "üìà LEARNING METRICS\n",
            "======================================================================\n",
            "\n",
            "1st Run: 4 learning events\n",
            "2nd Run: 2 learning events\n",
            "\n",
            "Improvement: 2 fewer learning events needed!\n",
            "\n",
            "üí° Fewer learning events means the prompt is better optimized!\n"
          ]
        }
      ],
      "source": [
        "print(\"üîÑ AFTER LEARNING (Second Run with Evolved Prompt)\\n\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "second_run_learning = []\n",
        "second_run_outputs = []  # Store outputs for comparison\n",
        "\n",
        "for i, task in enumerate(EXTRACTION_TASKS, 1):\n",
        "    print(f\"\\nüìù Task {i}/{len(EXTRACTION_TASKS)}\")\n",
        "    \n",
        "    # Run extraction\n",
        "    output, learning_result = await extract_with_scope(\n",
        "        task['instruction'],\n",
        "        task['text'],\n",
        "        f\"task_{i}_round2\"\n",
        "    )\n",
        "    \n",
        "    second_run_outputs.append(output)\n",
        "    print(f\"‚úì Output: {output}\")\n",
        "    \n",
        "    if learning_result:\n",
        "        second_run_learning.append(learning_result)\n",
        "        print(f\"üìö New learning event\")\n",
        "    else:\n",
        "        print(f\"‚úì No new learning needed (prompt already optimized!)\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"üìä SIDE-BY-SIDE COMPARISON\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Compare outputs for each task\n",
        "improvements_found = False\n",
        "for i, task in enumerate(EXTRACTION_TASKS):\n",
        "    before = first_run_outputs[i]\n",
        "    after = second_run_outputs[i]\n",
        "    \n",
        "    if before != after:\n",
        "        improvements_found = True\n",
        "        print(f\"\\nüìù Task {i+1}: {task['instruction']}\")\n",
        "        print(f\"   Text: {task['text'][:60]}...\")\n",
        "        print(f\"\\n   ‚ùå Before: {before}\")\n",
        "        print(f\"   ‚úÖ After:  {after}\")\n",
        "        print(f\"   üí° Improvement: Output is now more consistent/normalized\")\n",
        "\n",
        "if not improvements_found:\n",
        "    print(\"\\n‚ö†Ô∏è  Outputs are identical - learning is happening but not visible in final outputs.\")\n",
        "    print(\"This suggests the tasks may need adjustment to show clearer improvements.\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"üìà LEARNING METRICS\")\n",
        "print(\"=\" * 70)\n",
        "print(f\"\\n1st Run: {len(learning_events)} learning events\")\n",
        "print(f\"2nd Run: {len(second_run_learning)} learning events\")\n",
        "print(f\"\\nImprovement: {len(learning_events) - len(second_run_learning)} fewer learning events needed!\")\n",
        "print(\"\\nüí° Fewer learning events means the prompt is better optimized!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Understanding the Results\n",
        "\n",
        "What just happened?\n",
        "\n",
        "### First Run (BEFORE Learning)\n",
        "- Started with a basic, generic prompt\n",
        "- Outputs may have inconsistencies (mixed case, uneven formatting, etc.)\n",
        "- SCOPE observed the outputs and identified improvement patterns\n",
        "- Generated strategic rules to address issues\n",
        "\n",
        "### Second Run (AFTER Learning)\n",
        "- Used the evolved prompt with learned strategic rules\n",
        "- Outputs should be more normalized and consistent\n",
        "- SCOPE found fewer (or no) issues to fix\n",
        "- The prompt is now optimized!\n",
        "\n",
        "### Key Insights\n",
        "\n",
        "**Look for visible improvements:**\n",
        "- ‚úÖ **Email normalization** (Tasks 1 & 2): `SUPPORT@COMPANY.COM` ‚Üí `support@company.com`, brackets removed\n",
        "- ‚úÖ **Date standardization** (Tasks 3 & 4): `January 1st 2025` ‚Üí `2025-01-01`, consistent YYYY-MM-DD\n",
        "- ‚úÖ **Phone cleaning** (Task 5): `(555)123.4567` ‚Üí consistent format, cleaned up\n",
        "- ‚úÖ **Consistency across similar tasks**: Same instruction = same formatting style\n",
        "\n",
        "**Metric validation:**\n",
        "- **Fewer learning events** = Prompt is already better optimized\n",
        "- **Visible output improvements** = Rules are actually working\n",
        "\n",
        "If outputs look identical, the tasks may need adjustment to better demonstrate learning!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Key Takeaways\n",
        "\n",
        "1. **Automatic Optimization**: SCOPE improves prompts without manual engineering\n",
        "2. **Observable Learning**: You can see what SCOPE learns in real-time\n",
        "3. **Measurable Results**: Fewer learning events = better prompts\n",
        "4. **Persistent Memory**: Rules are saved and reused across runs\n",
        "5. **LangChain Integration**: Works seamlessly with existing LangChain code\n",
        "\n",
        "## Try It Yourself!\n",
        "\n",
        "Experiment with:\n",
        "- Different extraction tasks\n",
        "- More iterations (run 10-15 tasks)\n",
        "- Other domains (classification, summarization, etc.)\n",
        "- Different models\n",
        "\n",
        "The more SCOPE observes, the better it gets!\n",
        "\n",
        "## Next Steps\n",
        "\n",
        "Ready to see more? Try these demos:\n",
        "\n",
        "### 1. Simple Demo (Command Line)\n",
        "Run the extraction demo from your terminal:\n",
        "```bash\n",
        "# Single run (~2 min)\n",
        "python simple_demo.py\n",
        "\n",
        "# See learning over 10 iterations (~20 min)\n",
        "python simple_compare.py --iterations 10\n",
        "```\n",
        "\n",
        "### 2. Research Assistant (Production Example)\n",
        "See SCOPE optimize a real multi-agent research system:\n",
        "```bash\n",
        "# Full research assistant with 5 learning agents\n",
        "python main.py\n",
        "\n",
        "# Compare learning over 10 iterations (~50 min)\n",
        "python compare_scope_impact.py --iterations 10\n",
        "```\n",
        "\n",
        "**What's different in the research assistant?**\n",
        "- üéØ **5 agents learning**: Questions, web search, Wikipedia, writing, coordination\n",
        "- üéì **Source quality assessment**: Academic vs blog detection (0-10 scoring)\n",
        "- ‚ö° **Thoroughness mode**: 7-dimension analysis for higher quality rules\n",
        "- üìà **Proven results**: +31% quality improvement in 5 iterations\n",
        "\n",
        "### 3. Documentation\n",
        "- **Architecture**: `docs/SCOPE_ARCHITECTURE.md` - See the 5-agent learning pipeline\n",
        "- **Implementation**: `docs/IMPLEMENTATION_GUIDE.md` - Complete usage guide\n",
        "- **Source Quality**: `docs/SOURCE_QUALITY_LEARNING.md` - How academic detection works\n",
        "\n",
        "### 4. Custom Integration\n",
        "Add SCOPE to your own LangChain applications following the pattern shown in this notebook!"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
