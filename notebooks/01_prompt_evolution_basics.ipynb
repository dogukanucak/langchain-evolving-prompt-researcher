{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Prompt Evolution with SCOPE\n",
        "\n",
        "Welcome to this tutorial on **automatic prompt optimization**!\n",
        "\n",
        "## What You'll Learn\n",
        "\n",
        "In this notebook, you'll discover how AI systems can automatically improve their own prompts through observation and learning. We'll use a simple information extraction task to demonstrate:\n",
        "\n",
        "- üìö How SCOPE (Self-Correcting Optimal Prompt Evolution) works\n",
        "- üîÑ How prompts evolve automatically over time\n",
        "- üìä How to measure improvement through iterative learning\n",
        "- üéØ Real-world application with LangChain\n",
        "\n",
        "## Context\n",
        "\n",
        "Traditional AI systems use **static prompts** - they never change or improve. But what if your AI could learn from experience and automatically optimize its own instructions? That's exactly what SCOPE enables.\n",
        "\n",
        "Think of it like a student who:\n",
        "1. Completes a task\n",
        "2. Reviews what went well and what didn't\n",
        "3. Updates their approach for next time\n",
        "4. Gets better with each attempt\n",
        "\n",
        "SCOPE does this automatically, with no manual prompt engineering required!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup\n",
        "\n",
        "First, let's install the required packages and set up our environment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%capture --no-stderr\n",
        "%pip install --quiet -U langchain_openai langchain_core scope-optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os, getpass\n",
        "\n",
        "def _set_env(var: str):\n",
        "    if not os.environ.get(var):\n",
        "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
        "\n",
        "_set_env(\"OPENAI_API_KEY\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## The Concept: Before and After\n",
        "\n",
        "Let's understand what we're building:\n",
        "\n",
        "### Without SCOPE (Traditional Approach)\n",
        "```\n",
        "Static Prompt ‚Üí LLM ‚Üí Output\n",
        "     ‚Üì\n",
        "  Never changes!\n",
        "```\n",
        "\n",
        "### With SCOPE (Evolving Approach)\n",
        "```\n",
        "Initial Prompt ‚Üí LLM ‚Üí Output\n",
        "      ‚Üì                  ‚Üì\n",
        "      ‚Üì          SCOPE Observes\n",
        "      ‚Üì                  ‚Üì\n",
        "      ‚Üì          Learns Patterns\n",
        "      ‚Üì                  ‚Üì\n",
        "Improved Prompt ‚Üê Updates Rules\n",
        "```\n",
        "\n",
        "The magic happens in the learning loop - SCOPE observes what works and what doesn't, then automatically generates improvement rules!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Our Simple Task: Information Extraction\n",
        "\n",
        "We'll use information extraction as our example because:\n",
        "- ‚úÖ It's easy to understand\n",
        "- ‚úÖ Results are measurable\n",
        "- ‚úÖ Improvements are visible\n",
        "\n",
        "We'll ask the AI to extract information like emails, names, and phone numbers from text. As it completes tasks, SCOPE will learn how to do this better."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: The Base Prompt (Before Learning)\n",
        "\n",
        "Let's start with a simple, basic prompt. This is what the AI begins with - no optimization yet."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "BASE_EXTRACTION_PROMPT = \"\"\"You are an information extraction specialist.\n",
        "Your task is to extract requested information from text accurately.\n",
        "\n",
        "## Core Instructions:\n",
        "- Extract only the requested information\n",
        "- Be accurate and precise\n",
        "- If information is missing, state \"Not found\"\n",
        "- Provide clean, structured output\n",
        "\"\"\"\n",
        "\n",
        "print(\"üìã Base Prompt:\")\n",
        "print(BASE_EXTRACTION_PROMPT)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This prompt is good, but generic. It doesn't have specific strategies for handling edge cases, formatting output consistently, or dealing with ambiguous data. **This is where SCOPE comes in!**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Define Extraction Tasks\n",
        "\n",
        "Let's create a variety of extraction tasks. Each one will teach SCOPE something different:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "EXTRACTION_TASKS = [\n",
        "    # Simple extraction\n",
        "    {\n",
        "        \"instruction\": \"Extract the email address\",\n",
        "        \"text\": \"Contact John Doe at john.doe@example.com for support\"\n",
        "    },\n",
        "    \n",
        "    # Multiple fields\n",
        "    {\n",
        "        \"instruction\": \"Parse and extract: name, age, and city\",\n",
        "        \"text\": \"Name: Jane Smith, Age: 28, City: Boston\"\n",
        "    },\n",
        "    \n",
        "    # Missing data (edge case)\n",
        "    {\n",
        "        \"instruction\": \"Extract the phone number\",\n",
        "        \"text\": \"You can email us at support@company.com\"\n",
        "    },\n",
        "    \n",
        "    # Malformed data\n",
        "    {\n",
        "        \"instruction\": \"Extract name, age, city, and phone\",\n",
        "        \"text\": \"name:John|age:|city:NYC|phone:555-0123\"\n",
        "    },\n",
        "    \n",
        "    # Multiple items\n",
        "    {\n",
        "        \"instruction\": \"Extract all email addresses\",\n",
        "        \"text\": \"Team: alice@test.com, Bob <bob@example.org>, charlie@mail.net\"\n",
        "    },\n",
        "]\n",
        "\n",
        "print(f\"‚úÖ Created {len(EXTRACTION_TASKS)} diverse extraction tasks\")\n",
        "print(\"\\nThese tasks cover: simple extraction, multiple fields, missing data, malformed data, and multiple items\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Set Up LangChain\n",
        "\n",
        "Now let's create our LangChain chat model. We'll use GPT-4o for high-quality extractions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.messages import SystemMessage, HumanMessage\n",
        "\n",
        "# Initialize the chat model\n",
        "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
        "\n",
        "print(\"‚úÖ LangChain ChatOpenAI initialized\")\n",
        "print(\"   Model: gpt-4o\")\n",
        "print(\"   Temperature: 0 (deterministic)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Initialize SCOPE\n",
        "\n",
        "Here's where the magic begins! SCOPE will observe each task completion and learn improvement patterns."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from scope import SCOPEOptimizer\n",
        "from scope.models import create_openai_model\n",
        "\n",
        "# Create SCOPE's model (for analyzing and learning)\n",
        "scope_model = create_openai_model(\n",
        "    model=\"gpt-4o\",\n",
        "    api_key=os.environ[\"OPENAI_API_KEY\"]\n",
        ")\n",
        "\n",
        "# Initialize SCOPE optimizer\n",
        "optimizer = SCOPEOptimizer(\n",
        "    synthesizer_model=scope_model,\n",
        "    exp_path=\"./scope_data\",  # Where to save learned rules\n",
        "    enable_quality_analysis=True,  # Analyze quality after each task\n",
        "    quality_analysis_frequency=1,  # Check every task\n",
        "    synthesis_mode=\"efficiency\",  # Fast learning mode\n",
        "    store_history=True  # Keep learning history\n",
        ")\n",
        "\n",
        "print(\"‚úÖ SCOPE Optimizer initialized\")\n",
        "print(\"   üìä Quality analysis: Enabled\")\n",
        "print(\"   üíæ Learning history: Stored\")\n",
        "print(\"   ‚ö° Mode: Efficiency (fast learning)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### What do these parameters mean?\n",
        "\n",
        "- **enable_quality_analysis**: After each task, SCOPE analyzes if the output could be better\n",
        "- **quality_analysis_frequency**: How often to check (1 = every task)\n",
        "- **synthesis_mode**: \"efficiency\" learns quickly, \"comprehensive\" is more thorough\n",
        "- **store_history**: Keeps a record of all learning events"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: First Run - Observe Learning\n",
        "\n",
        "Let's run through our tasks and watch SCOPE learn in real-time!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import asyncio\n",
        "\n",
        "async def extract_with_scope(instruction, text, task_id):\n",
        "    \"\"\"Extract information and let SCOPE observe.\"\"\"\n",
        "    \n",
        "    # Get current prompt (starts with base, evolves over time)\n",
        "    strategic_rules = optimizer.get_strategic_rules_for_agent(\"info_extractor\")\n",
        "    current_prompt = BASE_EXTRACTION_PROMPT\n",
        "    if strategic_rules:\n",
        "        current_prompt += f\"\\n\\n## Strategic Guidelines (Learned):\\n{strategic_rules}\"\n",
        "    \n",
        "    # Create messages\n",
        "    messages = [\n",
        "        SystemMessage(content=current_prompt),\n",
        "        HumanMessage(content=f\"{instruction}\\n\\nText: {text}\")\n",
        "    ]\n",
        "    \n",
        "    # Get response from LLM\n",
        "    response = llm.invoke(messages)\n",
        "    output = response.content\n",
        "    \n",
        "    # Let SCOPE observe and learn\n",
        "    result = await optimizer.on_step_complete(\n",
        "        agent_name=\"info_extractor\",\n",
        "        agent_role=\"Information Extraction Specialist\",\n",
        "        task=f\"{instruction} | Text: {text}\",\n",
        "        model_output=output,\n",
        "        observations=f\"Extracted from: '{text[:50]}...'\",\n",
        "        error=None,\n",
        "        current_system_prompt=current_prompt,\n",
        "        task_id=task_id\n",
        "    )\n",
        "    \n",
        "    return output, result\n",
        "\n",
        "# Run the tasks\n",
        "print(\"üöÄ Starting extraction tasks...\\n\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "learning_events = []\n",
        "\n",
        "for i, task in enumerate(EXTRACTION_TASKS, 1):\n",
        "    print(f\"\\nüìù Task {i}/{len(EXTRACTION_TASKS)}\")\n",
        "    print(f\"Instruction: {task['instruction']}\")\n",
        "    print(f\"Text: {task['text']}\")\n",
        "    \n",
        "    # Run extraction\n",
        "    output, learning_result = await extract_with_scope(\n",
        "        task['instruction'],\n",
        "        task['text'],\n",
        "        f\"task_{i}\"\n",
        "    )\n",
        "    \n",
        "    print(f\"\\n‚úì Output: {output}\")\n",
        "    \n",
        "    # Check if SCOPE learned something\n",
        "    if learning_result:\n",
        "        guideline, guideline_type = learning_result\n",
        "        learning_events.append({\"task\": i, \"type\": guideline_type, \"rule\": guideline})\n",
        "        print(f\"\\nüìö SCOPE LEARNED ({guideline_type.upper()}):\")\n",
        "        print(f\"   {guideline[:120]}...\")\n",
        "    \n",
        "    print(\"\\n\" + \"-\" * 70)\n",
        "\n",
        "print(f\"\\n‚úÖ Completed {len(EXTRACTION_TASKS)} tasks\")\n",
        "print(f\"üìö SCOPE learning events: {len(learning_events)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"üìä Learning Summary\\n\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "if learning_events:\n",
        "    print(f\"\\nTotal learning events: {len(learning_events)}\\n\")\n",
        "    \n",
        "    for event in learning_events:\n",
        "        print(f\"Task {event['task']} - {event['type'].upper()}:\")\n",
        "        print(f\"  {event['rule'][:100]}...\")\n",
        "        print()\n",
        "else:\n",
        "    print(\"No learning events recorded.\")\n",
        "\n",
        "# Get the complete evolved prompt\n",
        "strategic_rules = optimizer.get_strategic_rules_for_agent(\"info_extractor\")\n",
        "evolved_prompt = BASE_EXTRACTION_PROMPT\n",
        "if strategic_rules:\n",
        "    evolved_prompt += f\"\\n\\n## Strategic Guidelines (Learned):\\n{strategic_rules}\"\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"EVOLVED PROMPT (After Learning)\")\n",
        "print(\"=\" * 70)\n",
        "print(evolved_prompt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 7: Compare Before and After\n",
        "\n",
        "Now let's run the same tasks again with the evolved prompt and compare:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"üîÑ Running tasks again with evolved prompt...\\n\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "second_run_learning = []\n",
        "\n",
        "for i, task in enumerate(EXTRACTION_TASKS, 1):\n",
        "    print(f\"\\nüìù Task {i}/{len(EXTRACTION_TASKS)}\")\n",
        "    \n",
        "    # Run extraction\n",
        "    output, learning_result = await extract_with_scope(\n",
        "        task['instruction'],\n",
        "        task['text'],\n",
        "        f\"task_{i}_round2\"\n",
        "    )\n",
        "    \n",
        "    print(f\"‚úì Output: {output}\")\n",
        "    \n",
        "    if learning_result:\n",
        "        second_run_learning.append(learning_result)\n",
        "        print(f\"üìö New learning event\")\n",
        "    else:\n",
        "        print(f\"‚úì No new learning needed (prompt already optimized!)\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"COMPARISON\")\n",
        "print(\"=\" * 70)\n",
        "print(f\"\\n1st Run: {len(learning_events)} learning events\")\n",
        "print(f\"2nd Run: {len(second_run_learning)} learning events\")\n",
        "print(f\"\\nImprovement: {len(learning_events) - len(second_run_learning)} fewer learning events needed!\")\n",
        "print(\"\\nüí° This means the prompt is already better optimized.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Understanding the Results\n",
        "\n",
        "What just happened?\n",
        "\n",
        "### First Run (Baseline)\n",
        "- Started with a basic prompt\n",
        "- Completed all tasks\n",
        "- SCOPE observed multiple opportunities for improvement\n",
        "- Generated strategic rules\n",
        "\n",
        "### Second Run (Optimized)\n",
        "- Used the evolved prompt with learned rules\n",
        "- Completed same tasks\n",
        "- SCOPE found fewer (or no) issues\n",
        "- Prompt is already better!\n",
        "\n",
        "### Key Insight\n",
        "**Fewer learning events = better prompts!**\n",
        "\n",
        "When SCOPE finds fewer things to improve, it means the prompt is already doing a good job."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Key Takeaways\n",
        "\n",
        "1. **Automatic Optimization**: SCOPE improves prompts without manual engineering\n",
        "2. **Observable Learning**: You can see what SCOPE learns in real-time\n",
        "3. **Measurable Results**: Fewer learning events = better prompts\n",
        "4. **Persistent Memory**: Rules are saved and reused across runs\n",
        "5. **LangChain Integration**: Works seamlessly with existing LangChain code\n",
        "\n",
        "## Try It Yourself!\n",
        "\n",
        "Experiment with:\n",
        "- Different extraction tasks\n",
        "- More iterations (run 10-15 tasks)\n",
        "- Other domains (classification, summarization, etc.)\n",
        "- Different models\n",
        "\n",
        "The more SCOPE observes, the better it gets!\n",
        "\n",
        "## Next Steps\n",
        "\n",
        "Want to learn more? Check out:\n",
        "- **Complex Scenarios**: See SCOPE optimize multi-agent research workflows\n",
        "- **Iterative Learning**: Run the same task 10-20 times and track improvement\n",
        "- **Custom Integration**: Add SCOPE to your own LangChain applications"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
